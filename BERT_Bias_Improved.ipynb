{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_Bias_Improved.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chetan-parthiban/Conceptors/blob/master/BERT_Bias_Improved.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUUKCaACVZ0W",
        "colab_type": "text"
      },
      "source": [
        "##Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdCIHeqmVKtT",
        "colab_type": "code",
        "outputId": "598b851b-b9d0-4c1e-c3d0-55105f1868e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "!pip install pytorch-pretrained-bert\n",
        "!pip install mlxtend"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 24.2MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 12.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 9.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.9.162)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.16.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.28.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2018.1.10)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2019.3.9)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.162 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.12.162)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.2.1)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.162->boto3->pytorch-pretrained-bert) (0.14)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.162->boto3->pytorch-pretrained-bert) (2.5.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.162->boto3->pytorch-pretrained-bert) (1.12.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wgxh7zA5VPmw",
        "colab_type": "code",
        "outputId": "8ef4de15-8ec8-4332-efa1-2d37bccfa0b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, optim\n",
        "import numpy as np\n",
        "from numpy.linalg import inv\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "%matplotlib inline\n",
        "dtype = torch.long\n",
        "device = torch.device('cuda:0')\n",
        "\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
        "import logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1gQkqP8VT6X",
        "colab_type": "code",
        "outputId": "11741a8d-79d2-4279-892e-c1663fe5f3c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "# Gender word lists\n",
        "!git clone https://github.com/uclanlp/gn_glove\n",
        "!git clone https://github.com/uclanlp/corefBias\n",
        "!wget https://www.cs.cmu.edu/Groups/AI/areas/nlp/corpora/names/female.txt\n",
        "!wget https://www.cs.cmu.edu/Groups/AI/areas/nlp/corpora/names/male.txt\n",
        "    \n",
        "# our code for debiasing -- also includes word lists    \n",
        "!git clone https://github.com/jsedoc/ConceptorDebias\n",
        "\n",
        "# Get Winobias word lists\n",
        "winoWordsPath = './' + 'corefBias/WinoBias/wino/extra_gendered_words.txt'\n",
        "male_vino_extra = []\n",
        "female_vino_extra = []\n",
        "with open(winoWordsPath, \"r+\") as f_in:\n",
        "    for line in f_in:\n",
        "        male_vino_extra.append(line.split('\\t')[0])\n",
        "        female_vino_extra.append(line.strip().split('\\t')[1])\n",
        "\n",
        "# Get CMU word lists\n",
        "cmuMaleWordPath = './' + 'male.txt'\n",
        "male_cmu = []\n",
        "with open(cmuMaleWordPath, \"r+\") as f_in:\n",
        "  for line in f_in:\n",
        "    w = line.strip()\n",
        "    if len(w)>0 and w[0] != '#':\n",
        "      male_cmu.append(w)\n",
        "cmuFemaleWordPath = './' + 'female.txt'\n",
        "female_cmu = []\n",
        "with open(cmuFemaleWordPath, \"r+\") as f_in:\n",
        "  for line in f_in:\n",
        "    w = line.strip()\n",
        "    if len(w)>0 and w[0] != '#':\n",
        "      female_cmu.append(w)\n",
        "    \n",
        "# Get gnGlove word lists\n",
        "gnGloveFemaleWordPath = './' + 'gn_glove/wordlist/female_word_file.txt'\n",
        "female_gnGlove = []\n",
        "with open(gnGloveFemaleWordPath, \"r+\") as f_in:\n",
        "    for line in f_in:\n",
        "        female_gnGlove.append(line.strip())\n",
        "gnGloveMaleWordPath = './' + 'gn_glove/wordlist/male_word_file.txt'\n",
        "male_gnGlove = []\n",
        "with open(gnGloveMaleWordPath, \"r+\") as f_in:\n",
        "    for line in f_in:\n",
        "        male_gnGlove.append(line.strip())\n",
        "    \n",
        "# Get WEAT lists and conceptor functionality\n",
        "from ConceptorDebias.Conceptors.conceptor_fxns import *\n",
        "from ConceptorDebias.lists import WEAT_lists\n",
        "WEATLists = WEAT_lists.WEATLists()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gn_glove'...\n",
            "remote: Enumerating objects: 48, done.\u001b[K\n",
            "remote: Counting objects: 100% (48/48), done.\u001b[K\n",
            "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "remote: Total 162 (delta 18), reused 25 (delta 9), pack-reused 114\u001b[K\n",
            "Receiving objects: 100% (162/162), 73.36 KiB | 790.00 KiB/s, done.\n",
            "Resolving deltas: 100% (64/64), done.\n",
            "Cloning into 'corefBias'...\n",
            "remote: Enumerating objects: 14, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 471 (delta 3), reused 0 (delta 0), pack-reused 457\u001b[K\n",
            "Receiving objects: 100% (471/471), 84.18 MiB | 31.00 MiB/s, done.\n",
            "Resolving deltas: 100% (273/273), done.\n",
            "--2019-06-07 17:14:31--  https://www.cs.cmu.edu/Groups/AI/areas/nlp/corpora/names/female.txt\n",
            "Resolving www.cs.cmu.edu (www.cs.cmu.edu)... 128.2.42.95\n",
            "Connecting to www.cs.cmu.edu (www.cs.cmu.edu)|128.2.42.95|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 35751 (35K) [text/plain]\n",
            "Saving to: ‘female.txt’\n",
            "\n",
            "female.txt          100%[===================>]  34.91K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-06-07 17:14:32 (266 KB/s) - ‘female.txt’ saved [35751/35751]\n",
            "\n",
            "--2019-06-07 17:14:33--  https://www.cs.cmu.edu/Groups/AI/areas/nlp/corpora/names/male.txt\n",
            "Resolving www.cs.cmu.edu (www.cs.cmu.edu)... 128.2.42.95\n",
            "Connecting to www.cs.cmu.edu (www.cs.cmu.edu)|128.2.42.95|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20466 (20K) [text/plain]\n",
            "Saving to: ‘male.txt’\n",
            "\n",
            "male.txt            100%[===================>]  19.99K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-06-07 17:14:33 (160 MB/s) - ‘male.txt’ saved [20466/20466]\n",
            "\n",
            "Cloning into 'ConceptorDebias'...\n",
            "remote: Enumerating objects: 102, done.\u001b[K\n",
            "remote: Counting objects: 100% (102/102), done.\u001b[K\n",
            "remote: Compressing objects: 100% (95/95), done.\u001b[K\n",
            "remote: Total 410 (delta 53), reused 12 (delta 6), pack-reused 308\u001b[K\n",
            "Receiving objects: 100% (410/410), 3.73 MiB | 5.92 MiB/s, done.\n",
            "Resolving deltas: 100% (219/219), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXOMrhPMVV9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gender_list_pronouns = WEATLists.W_7_Male_terms + WEATLists.W_7_Female_terms + WEATLists.W_8_Male_terms + WEATLists.W_8_Female_terms\n",
        "gender_list_pronouns = list(set(gender_list_pronouns))\n",
        "\n",
        "pronouns_male = WEATLists.W_7_Male_terms + WEATLists.W_8_Male_terms\n",
        "pronouns_male = list(set(pronouns_male))\n",
        "pronouns_female = WEATLists.W_8_Female_terms + WEATLists.W_8_Female_terms\n",
        "pronouns_female = list(set(pronouns_female))\n",
        "\n",
        "\n",
        "gender_list_extended = male_vino_extra + female_vino_extra + male_gnGlove + female_gnGlove\n",
        "gender_list_extended = list(set(gender_list_extended))\n",
        "\n",
        "extended_male = male_vino_extra + male_gnGlove\n",
        "extended_male = list(set(extended_male))\n",
        "extended_female = female_vino_extra + female_gnGlove\n",
        "extended_female = list(set(extended_female))\n",
        "\n",
        "gender_list_propernouns = male_cmu + female_cmu\n",
        "gender_list_propernouns = list(set(gender_list_propernouns))\n",
        "\n",
        "propernouns_male = list(set(male_cmu))\n",
        "propernouns_female = list(set(female_cmu))\n",
        "\n",
        "gender_list_all = gender_list_pronouns + gender_list_extended + gender_list_propernouns\n",
        "gender_list_all = list(set(gender_list_all))\n",
        "\n",
        "all_male = list(set(pronouns_male + extended_male + propernouns_male))\n",
        "all_female = list(set(pronouns_female + extended_female + propernouns_female))\n",
        "\n",
        "career = list(set(WEATLists.W_6_Career))\n",
        "family = list(set(WEATLists.W_6_Family))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfFqZBdnVfOR",
        "colab_type": "text"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wt_vQpanVYuL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_model = 'bert-base-uncased'\n",
        "\n",
        "## Get BERT tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained(bert_model)\n",
        "model = BertForMaskedLM.from_pretrained(bert_model)\n",
        "model.eval()\n",
        "model.to('cuda')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUmlF1bcVkJ9",
        "colab_type": "code",
        "outputId": "76f2336b-b191-4101-8fff-6528fd856b57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "sentence_template = '[CLS] [MASK] likes [MASK] [SEP]'\n",
        "\n",
        "target1 = ['male', 'man', 'boy', 'brother', 'he', 'him', 'his', 'son']\n",
        "target2 = ['female', 'woman', 'girl', 'sister', 'she', 'her', 'hers', 'daughter']\n",
        "attribute1 = ['math', 'algebra', 'geometry', 'calculus', 'equations', 'computation', 'numbers', 'addition']\n",
        "attribute2 = ['poetry', 'art', 'dance', 'literature', 'novel', 'symphony', 'drama', 'sculpture']\n",
        "t_position = 1\n",
        "a_position = 3\n",
        "\n",
        "print('Target 1: ', target1)\n",
        "print('Target 2: ', target2)\n",
        "print('Attribute 1: ', attribute1)\n",
        "print('Attribute2 2: ', attribute2)\n",
        "\n",
        "template_token = tokenizer.tokenize(sentence_template)\n",
        "segments_ids = np.zeros(len(template_token))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target 1:  ['male', 'man', 'boy', 'brother', 'he', 'him', 'his', 'son']\n",
            "Target 2:  ['female', 'woman', 'girl', 'sister', 'she', 'her', 'hers', 'daughter']\n",
            "Attribute 1:  ['math', 'algebra', 'geometry', 'calculus', 'equations', 'computation', 'numbers', 'addition']\n",
            "Attribute2 2:  ['poetry', 'art', 'dance', 'literature', 'novel', 'symphony', 'drama', 'sculpture']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFvCuFm_VmoX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sentence_from_template(attribute, tokenized, pos):\n",
        "    \n",
        "    sentences = []\n",
        "\n",
        "    for atr in attribute:\n",
        "        temp = tokenized.copy()\n",
        "        temp[pos] = atr\n",
        "        sentences.append(temp)\n",
        "                \n",
        "    return sentences\n",
        "\n",
        "a1 = sentence_from_template(attribute1, template_token, a_position)\n",
        "a2 = sentence_from_template(attribute2, template_token, a_position)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceSYnoJlY9Co",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sentences_to_ids(sentences, tokenizer, pos):  \n",
        "    ids = []\n",
        "    attribute_ids = []\n",
        "    \n",
        "    for sentence in sentences:\n",
        "        sentence_ids = tokenizer.convert_tokens_to_ids(sentence)\n",
        "        sentence_attribute = tokenizer.convert_tokens_to_ids([sentence[pos]])\n",
        "        \n",
        "        ids.append(sentence_ids)\n",
        "        attribute_ids.append(sentence_attribute)\n",
        "        \n",
        "    return ids, attribute_ids\n",
        "\n",
        "target1_id = tokenizer.convert_tokens_to_ids(target1)\n",
        "target2_id = tokenizer.convert_tokens_to_ids(target2)\n",
        "\n",
        "a1_id, attribute_ids = sentences_to_ids(a1, tokenizer, a_position)\n",
        "a2_id, attribute_ids = sentences_to_ids(a2, tokenizer, a_position)\n",
        "\n",
        "masked = [tokenizer.convert_tokens_to_ids(template_token)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u939tQwugMeS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a1_tensor = torch.tensor(a1_id, device = device, dtype = dtype)\n",
        "a2_tensor = torch.tensor(a2_id, device = device, dtype = dtype)\n",
        "masked_tensor = torch.tensor(masked, device = device, dtype = dtype)\n",
        "segments_tensor = torch.tensor([segments_ids], device = device, dtype = dtype)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaemudu_hS1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "    p1 = model(a1_tensor, segments_tensor)\n",
        "    p2 = model(a2_tensor, segments_tensor)\n",
        "    p_init = model(masked_tensor, segments_tensor)\n",
        "    \n",
        "s = nn.Softmax(dim = 1)\n",
        "p1 = s(p1[:,t_position])\n",
        "p2 = s(p2[:,t_position])\n",
        "p_init = s(p_init[:,t_position])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hww9D5Vnh__p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p_targets1 = p1[:,target1_id]\n",
        "p_targets2 = p2[:,target1_id]\n",
        "p_targets_init1 = p_init[:,target1_id]\n",
        "\n",
        "p1_ratio = p_targets1 / p_targets_init1\n",
        "p2_ratio = p_targets2 / p_targets_init1\n",
        "\n",
        "\n",
        "logp1t1 = torch.log(p1_ratio)\n",
        "logp2t1 = torch.log(p2_ratio)\n",
        "\n",
        "meanlog1 = torch.mean(logp1t1, dim = 1)\n",
        "meanlog2 = torch.mean(logp2t1, dim = 1)\n",
        "\n",
        "s1 = torch.sum(meanlog1)\n",
        "s2 = torch.sum(meanlog2)\n",
        "\n",
        "diff1 = s1 - s2\n",
        "\n",
        "p_targets1 = p1[:,target2_id]\n",
        "p_targets2 = p2[:,target2_id]\n",
        "p_targets_init1 = p_init[:,target2_id]\n",
        "\n",
        "p1_ratio = p_targets1 / p_targets_init1\n",
        "p2_ratio = p_targets2 / p_targets_init1\n",
        "\n",
        "logp1t2 = torch.log(p1_ratio)\n",
        "logp2t2 = torch.log(p2_ratio)\n",
        "\n",
        "meanlog1 = torch.mean(logp1t2, dim = 1)\n",
        "meanlog2 = torch.mean(logp2t2, dim = 1)\n",
        "\n",
        "s1 = torch.sum(meanlog1)\n",
        "s2 = torch.sum(meanlog2)\n",
        "\n",
        "diff2 = s1 - s2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3ZfMYG98oum",
        "colab_type": "code",
        "outputId": "6ab21a93-e988-4455-f670-98a95f06174f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def permutation_test(t1a1,t1a2,t2a1,t2a2, sample_size = 10000):\n",
        "    \n",
        "    statistic = (torch.sum(torch.mean(t1a1, dim = 1)) - torch.sum(torch.mean(t1a2, dim = 1))) \\\n",
        "            - (torch.sum(torch.mean(t2a1, dim = 1)) - torch.sum(torch.mean(t2a2, dim = 1)))\n",
        "    data1 = torch.cat((logp1t1, logp1t2), dim = 1)\n",
        "    data2 = torch.cat((logp2t1, logp2t2), dim = 1)\n",
        "    sz = int(data1.size()[0]/2)\n",
        "\n",
        "    results = []\n",
        "    for _ in range(sample_size):\n",
        "        \n",
        "        perm = np.random.permutation(sz*2)\n",
        "        \n",
        "        d11 = data1[perm[0:sz]]\n",
        "        d12 = data1[perm[sz:]]\n",
        "        \n",
        "        d21 = data2[perm[0:sz]]\n",
        "        d22 = data2[perm[sz:]]\n",
        "        \n",
        "        t_stat = (torch.sum(torch.mean(d11, dim = 1)) - torch.sum(torch.mean(d21, dim = 1))) \\\n",
        "            - (torch.sum(torch.mean(d21, dim = 1)) - torch.sum(torch.mean(d22, dim = 1)))\n",
        "        \n",
        "        results.append(t_stat)\n",
        "        \n",
        "    results2 = [stat for stat in results if stat > statistic]\n",
        "    \n",
        "    p_value = len(results2)/sample_size\n",
        "    std = torch.std(torch.mean(torch.cat((logp1t1 - logp2t1, logp1t2 - logp2t2),1)))\n",
        "    effect_size = (torch.mean(torch.mean(t1a1, dim = 1)) - torch.mean(torch.mean(t1a2, dim = 1))) \\\n",
        "            - (torch.sum(torch.mean(t2a1, dim = 1)) - torch.mean(torch.mean(t2a2, dim = 1)))\n",
        "    \n",
        "    return p_value, effect_size.item()\n",
        "\n",
        "permutation_test(logp1t1,logp2t1,logp1t2,logp2t2, sample_size = 1000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.436, 7.504287242889404)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQ8Mi84dCyPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}